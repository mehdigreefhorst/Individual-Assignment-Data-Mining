{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Individual assignment Data mining \n",
    "### National Health and Nutrition Examination Survey\n",
    "\n",
    "For this assignment we have a set of 6 different files with data available from survey research. "
   ],
   "id": "c5961cde00497138"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-06T00:26:18.380281Z",
     "start_time": "2024-12-06T00:26:18.160725Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import LLMConnect\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, \n",
    "                             roc_auc_score, confusion_matrix, classification_report, \n",
    "                             silhouette_score)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing the data",
   "id": "baa53147e40d5418"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T00:26:19.359542Z",
     "start_time": "2024-12-06T00:26:19.296341Z"
    }
   },
   "cell_type": "code",
   "source": "df_diet = pd.read_csv(\"data/diet.csv\")",
   "id": "339c1647dca5ca29",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T00:26:19.852797Z",
     "start_time": "2024-12-06T00:26:19.848242Z"
    }
   },
   "cell_type": "code",
   "source": "[col for col in df_diet.columns if col.startswith(\"DR1\")]",
   "id": "b815f96f4759e470",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DR1DRSTZ',\n",
       " 'DR1EXMER',\n",
       " 'DR1DBIH',\n",
       " 'DR1DAY',\n",
       " 'DR1LANG',\n",
       " 'DR1MNRSP',\n",
       " 'DR1HELPD',\n",
       " 'DR1STY',\n",
       " 'DR1SKY',\n",
       " 'DR1TNUMF',\n",
       " 'DR1TKCAL',\n",
       " 'DR1TPROT',\n",
       " 'DR1TCARB',\n",
       " 'DR1TSUGR',\n",
       " 'DR1TFIBE',\n",
       " 'DR1TTFAT',\n",
       " 'DR1TSFAT',\n",
       " 'DR1TMFAT',\n",
       " 'DR1TPFAT',\n",
       " 'DR1TCHOL',\n",
       " 'DR1TATOC',\n",
       " 'DR1TATOA',\n",
       " 'DR1TRET',\n",
       " 'DR1TVARA',\n",
       " 'DR1TACAR',\n",
       " 'DR1TBCAR',\n",
       " 'DR1TCRYP',\n",
       " 'DR1TLYCO',\n",
       " 'DR1TLZ',\n",
       " 'DR1TVB1',\n",
       " 'DR1TVB2',\n",
       " 'DR1TNIAC',\n",
       " 'DR1TVB6',\n",
       " 'DR1TFOLA',\n",
       " 'DR1TFA',\n",
       " 'DR1TFF',\n",
       " 'DR1TFDFE',\n",
       " 'DR1TCHL',\n",
       " 'DR1TVB12',\n",
       " 'DR1TB12A',\n",
       " 'DR1TVC',\n",
       " 'DR1TVD',\n",
       " 'DR1TVK',\n",
       " 'DR1TCALC',\n",
       " 'DR1TPHOS',\n",
       " 'DR1TMAGN',\n",
       " 'DR1TIRON',\n",
       " 'DR1TZINC',\n",
       " 'DR1TCOPP',\n",
       " 'DR1TSODI',\n",
       " 'DR1TPOTA',\n",
       " 'DR1TSELE',\n",
       " 'DR1TCAFF',\n",
       " 'DR1TTHEO',\n",
       " 'DR1TALCO',\n",
       " 'DR1TMOIS',\n",
       " 'DR1TS040',\n",
       " 'DR1TS060',\n",
       " 'DR1TS080',\n",
       " 'DR1TS100',\n",
       " 'DR1TS120',\n",
       " 'DR1TS140',\n",
       " 'DR1TS160',\n",
       " 'DR1TS180',\n",
       " 'DR1TM161',\n",
       " 'DR1TM181',\n",
       " 'DR1TM201',\n",
       " 'DR1TM221',\n",
       " 'DR1TP182',\n",
       " 'DR1TP183',\n",
       " 'DR1TP184',\n",
       " 'DR1TP204',\n",
       " 'DR1TP205',\n",
       " 'DR1TP225',\n",
       " 'DR1TP226',\n",
       " 'DR1.300',\n",
       " 'DR1.320Z',\n",
       " 'DR1.330Z',\n",
       " 'DR1BWATZ',\n",
       " 'DR1TWS']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T00:26:20.861233Z",
     "start_time": "2024-12-06T00:26:20.434484Z"
    }
   },
   "cell_type": "code",
   "source": "df_diet[\"DR1CCMTX\"]",
   "id": "3f53cead66bc61d6",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'DR1CCMTX'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/Desktop/Individual Assignment Data Mining/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3804\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3805\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32mindex.pyx:167\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mindex.pyx:196\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'DR1CCMTX'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mdf_diet\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mDR1CCMTX\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Individual Assignment Data Mining/venv/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   4100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   4101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 4102\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4103\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   4104\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/Desktop/Individual Assignment Data Mining/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3807\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[1;32m   3808\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[1;32m   3809\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[1;32m   3810\u001B[0m     ):\n\u001B[1;32m   3811\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[0;32m-> 3812\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3813\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3814\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3815\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3816\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3817\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'DR1CCMTX'"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ",
   "id": "84278f894590f9ea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Analyzing the vegatarians\n",
    " order for us to analyze the vegatarians in the data, we must find the vegatarians. However, in the data there is no self reported vegatarian question. However, what is available is in a .xpt file on https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2013/DataFiles/DS1IDS_H.htm. In this file we can see what each user who is represented by a unique SEQN, what their daily food consisted out of. There are two separate data files, where we can find the food that has been eaten by the participant. DR1IFF_H.xpt  includes the food data of day 1 and DR2IFF_H.xpt contains the food data of day 2. Not every participant in the provided 5 data files from kaggle, has participated in the food eating evaluation interviews. So we will only take the rows where the sequence number exists in both food evaluating interviews and also in the general interview. \n",
    " \n",
    "In order to label the SEQN as vegetarian or non_vegatarian, we must implement a proxy to identify a vegetarian. As proxy we use whether an individual has eaten no meat, poultry or fish. "
   ],
   "id": "c80c576a430d5413"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T00:26:22.570690Z",
     "start_time": "2024-12-06T00:26:21.928415Z"
    }
   },
   "cell_type": "code",
   "source": "df_day1 = pd.read_sas(\"data/DR1IFF_H.xpt\")",
   "id": "e188d962b3024a9c",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "8a30c87a7133d097"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T00:26:22.894679Z",
     "start_time": "2024-12-06T00:26:22.889881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"A total of {len(df_day1.SEQN.unique())} unique SEQN numbers are in the dataset\")\n",
    "print(f\"A total of {len(df_day1)} rows are in the dataset, which means that each individual has reported {round(len(df_day1)/len(df_day1.SEQN.unique()), ndigits=1)} different food items on day 1\")"
   ],
   "id": "4ca8c3c060df8b29",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 8661 unique SEQN numbers are in the dataset\n",
      "A total of 131394 rows are in the dataset, which means that each individual has reported 15.2 different food items on day 1\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In the day 1 dataset, there are 8661 different participants who have reported 15.2 different food items for a total of 13194 total food items in day 1. \n",
    "\n",
    "We now want to evaluate the food items efficiently, we can use a metric which is the food group item namely \"DR1CCMTX\". This metric devides all possible food items in into 16 groups. Below you can see the results. We see that there is an error, the extreme negative value (5.4 * e-79), should be 0, but this might be due to the xpt reading of the food. So we should round the vlaues of DR1CCMTX"
   ],
   "id": "a66c3cb66fd2f159"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T00:26:23.637036Z",
     "start_time": "2024-12-06T00:26:23.633831Z"
    }
   },
   "cell_type": "code",
   "source": "df_day1.DR1CCMTX.unique()",
   "id": "2c8480cd9018aa1f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.39760535e-79, 1.00000000e+00, 9.00000000e+01, 2.00000000e+00,\n",
       "       3.00000000e+00, 5.00000000e+00, 1.10000000e+01, 1.00000000e+01,\n",
       "       9.00000000e+00, 1.20000000e+01, 4.00000000e+00, 1.40000000e+01,\n",
       "       6.00000000e+00, 8.00000000e+00, 1.30000000e+01, 7.00000000e+00])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T00:26:24.073378Z",
     "start_time": "2024-12-06T00:26:24.067779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_day1[\"DR1CCMTX\"] = round(df_day1[\"DR1CCMTX\"])\n",
    "occurrences = df_day1[\"DR1CCMTX\"].value_counts().sort_index()\n",
    "occurrences"
   ],
   "id": "8a9b720c927a3a83",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DR1CCMTX\n",
       "0.0     75335\n",
       "1.0     10947\n",
       "2.0      5466\n",
       "3.0      5300\n",
       "4.0      5337\n",
       "5.0     13313\n",
       "6.0       832\n",
       "7.0        52\n",
       "8.0       491\n",
       "9.0      3690\n",
       "10.0      666\n",
       "11.0     1781\n",
       "12.0     2653\n",
       "13.0      169\n",
       "14.0      721\n",
       "90.0     4641\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T00:26:24.527866Z",
     "start_time": "2024-12-06T00:26:24.506715Z"
    }
   },
   "cell_type": "code",
   "source": "len(df_day1[df_day1[\"DR1CCMTX\"] == 0][\"SEQN\"].unique())",
   "id": "64b8a60de19395fd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8648"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## First found challenge\n",
    "The food combination type metric \"DR1CCMTX\", includes a lot of 0 values. The value 0, refers to the food combination not having a specific code in the researchers coding system. We thought we might be able to be smart and exclude the participants that have eaten food that has food code 0. But this group consists 99.9% of the dataset, so we have to find a workaround. As there are only 721 instances of food that participants have eaten food that belongs to the poultry, meat and fish group, which is number 14\n",
    "\n",
    "You can see a table that includes the foodtypes and their respective code below\n",
    "\n",
    "![IMG](Images/Table-food-type-codes.png)\n",
    "source:  https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2013/DataFiles/DRXFCD_H.htm"
   ],
   "id": "6d2f182849e6c178"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## How to label vegetarians\n",
    "\n",
    "As the group of combination food codes has 57% undefined values, who might contain meat or fish. We must use a different approach to find out who in this dataset is vegetarian. There is another column that identifies what the food type can be in this dataset. It is the column DR1IFDCD, which has a column description of the USDA food code of the food, (called DR2IFDCD in day 2 dataset). So by identifying which DR1IFDCD food codes contain meat, poultry or fish, we should be able to correctly link participants to being vegetarian. \n",
    "\n",
    "The only missing piece that is left is to find out which food codes contain meat and which do not. Luckily, there is a description of food codes file available at the "
   ],
   "id": "dd7d8cc55f6b8d3c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T00:26:25.704885Z",
     "start_time": "2024-12-06T00:26:25.686188Z"
    }
   },
   "cell_type": "code",
   "source": "df_day1",
   "id": "7f4a705ed5223def",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           SEQN        WTDRD1        WTDR2D  DR1ILINE  DR1DRSTZ  DR1EXMER  \\\n",
       "0       73557.0  16888.327864  12930.890649       1.0       1.0      49.0   \n",
       "1       73557.0  16888.327864  12930.890649       2.0       1.0      49.0   \n",
       "2       73557.0  16888.327864  12930.890649       3.0       1.0      49.0   \n",
       "3       73557.0  16888.327864  12930.890649       4.0       1.0      49.0   \n",
       "4       73557.0  16888.327864  12930.890649       5.0       1.0      49.0   \n",
       "...         ...           ...           ...       ...       ...       ...   \n",
       "131389  83731.0   5805.674812   4339.132077      23.0       1.0      49.0   \n",
       "131390  83731.0   5805.674812   4339.132077      24.0       1.0      49.0   \n",
       "131391  83731.0   5805.674812   4339.132077      25.0       1.0      49.0   \n",
       "131392  83731.0   5805.674812   4339.132077      26.0       1.0      49.0   \n",
       "131393  83731.0   5805.674812   4339.132077      27.0       1.0      49.0   \n",
       "\n",
       "        DRABF  DRDINT  DR1DBIH  DR1DAY  ...      DR1IM181      DR1IM201  \\\n",
       "0         2.0     2.0      6.0     2.0  ...  3.595000e+00  3.400000e-02   \n",
       "1         2.0     2.0      6.0     2.0  ...  5.397605e-79  5.397605e-79   \n",
       "2         2.0     2.0      6.0     2.0  ...  5.397605e-79  5.397605e-79   \n",
       "3         2.0     2.0      6.0     2.0  ...  8.100000e-02  5.397605e-79   \n",
       "4         2.0     2.0      6.0     2.0  ...  2.600000e-02  5.397605e-79   \n",
       "...       ...     ...      ...     ...  ...           ...           ...   \n",
       "131389    2.0     2.0     12.0     6.0  ...  3.798000e+00  3.800000e-02   \n",
       "131390    2.0     2.0     12.0     6.0  ...  5.260000e-01  5.000000e-03   \n",
       "131391    2.0     2.0     12.0     6.0  ...  1.483000e+00  1.500000e-02   \n",
       "131392    2.0     2.0     12.0     6.0  ...  6.830000e-01  5.397605e-79   \n",
       "131393    2.0     2.0     12.0     6.0  ...  5.397605e-79  5.397605e-79   \n",
       "\n",
       "            DR1IM221      DR1IP182      DR1IP183      DR1IP184      DR1IP204  \\\n",
       "0       1.000000e-03  9.490000e-01  1.080000e-01  5.397605e-79  5.100000e-02   \n",
       "1       5.397605e-79  4.000000e-03  5.397605e-79  5.397605e-79  5.397605e-79   \n",
       "2       5.397605e-79  5.397605e-79  5.397605e-79  5.397605e-79  5.397605e-79   \n",
       "3       5.397605e-79  1.030000e-01  3.100000e-02  5.397605e-79  5.397605e-79   \n",
       "4       5.397605e-79  2.400000e-02  9.000000e-03  5.397605e-79  5.397605e-79   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "131389  5.397605e-79  3.372000e+00  4.790000e-01  5.397605e-79  5.397605e-79   \n",
       "131390  5.397605e-79  4.730000e-01  8.200000e-02  5.397605e-79  5.397605e-79   \n",
       "131391  5.397605e-79  1.346000e+00  1.980000e-01  5.397605e-79  5.397605e-79   \n",
       "131392  5.397605e-79  6.000000e-02  2.500000e-02  5.397605e-79  5.397605e-79   \n",
       "131393  5.397605e-79  5.397605e-79  5.397605e-79  5.397605e-79  5.397605e-79   \n",
       "\n",
       "            DR1IP205      DR1IP225      DR1IP226  \n",
       "0       1.000000e-03  5.397605e-79  1.000000e-02  \n",
       "1       5.397605e-79  5.397605e-79  5.397605e-79  \n",
       "2       5.397605e-79  5.397605e-79  5.397605e-79  \n",
       "3       5.397605e-79  5.397605e-79  5.397605e-79  \n",
       "4       5.397605e-79  5.397605e-79  5.397605e-79  \n",
       "...              ...           ...           ...  \n",
       "131389  5.397605e-79  5.397605e-79  5.397605e-79  \n",
       "131390  5.397605e-79  5.397605e-79  5.397605e-79  \n",
       "131391  5.397605e-79  5.397605e-79  5.397605e-79  \n",
       "131392  5.397605e-79  5.397605e-79  5.397605e-79  \n",
       "131393  5.397605e-79  5.397605e-79  5.397605e-79  \n",
       "\n",
       "[131394 rows x 84 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>WTDRD1</th>\n",
       "      <th>WTDR2D</th>\n",
       "      <th>DR1ILINE</th>\n",
       "      <th>DR1DRSTZ</th>\n",
       "      <th>DR1EXMER</th>\n",
       "      <th>DRABF</th>\n",
       "      <th>DRDINT</th>\n",
       "      <th>DR1DBIH</th>\n",
       "      <th>DR1DAY</th>\n",
       "      <th>...</th>\n",
       "      <th>DR1IM181</th>\n",
       "      <th>DR1IM201</th>\n",
       "      <th>DR1IM221</th>\n",
       "      <th>DR1IP182</th>\n",
       "      <th>DR1IP183</th>\n",
       "      <th>DR1IP184</th>\n",
       "      <th>DR1IP204</th>\n",
       "      <th>DR1IP205</th>\n",
       "      <th>DR1IP225</th>\n",
       "      <th>DR1IP226</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73557.0</td>\n",
       "      <td>16888.327864</td>\n",
       "      <td>12930.890649</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.595000e+00</td>\n",
       "      <td>3.400000e-02</td>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>9.490000e-01</td>\n",
       "      <td>1.080000e-01</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.100000e-02</td>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>1.000000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73557.0</td>\n",
       "      <td>16888.327864</td>\n",
       "      <td>12930.890649</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>4.000000e-03</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73557.0</td>\n",
       "      <td>16888.327864</td>\n",
       "      <td>12930.890649</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73557.0</td>\n",
       "      <td>16888.327864</td>\n",
       "      <td>12930.890649</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.100000e-02</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>1.030000e-01</td>\n",
       "      <td>3.100000e-02</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73557.0</td>\n",
       "      <td>16888.327864</td>\n",
       "      <td>12930.890649</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.600000e-02</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>2.400000e-02</td>\n",
       "      <td>9.000000e-03</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131389</th>\n",
       "      <td>83731.0</td>\n",
       "      <td>5805.674812</td>\n",
       "      <td>4339.132077</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.798000e+00</td>\n",
       "      <td>3.800000e-02</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>3.372000e+00</td>\n",
       "      <td>4.790000e-01</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131390</th>\n",
       "      <td>83731.0</td>\n",
       "      <td>5805.674812</td>\n",
       "      <td>4339.132077</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.260000e-01</td>\n",
       "      <td>5.000000e-03</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>4.730000e-01</td>\n",
       "      <td>8.200000e-02</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131391</th>\n",
       "      <td>83731.0</td>\n",
       "      <td>5805.674812</td>\n",
       "      <td>4339.132077</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.483000e+00</td>\n",
       "      <td>1.500000e-02</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>1.346000e+00</td>\n",
       "      <td>1.980000e-01</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131392</th>\n",
       "      <td>83731.0</td>\n",
       "      <td>5805.674812</td>\n",
       "      <td>4339.132077</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.830000e-01</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>6.000000e-02</td>\n",
       "      <td>2.500000e-02</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131393</th>\n",
       "      <td>83731.0</td>\n",
       "      <td>5805.674812</td>\n",
       "      <td>4339.132077</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.397605e-79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131394 rows × 84 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Importing dataset which contains food code descriptions\n",
    "In this dataset we can find what each of the foodcodes means in plain english."
   ],
   "id": "43c5b42ffcb3fc7c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T00:42:28.533118Z",
     "start_time": "2024-12-06T00:42:28.526125Z"
    }
   },
   "cell_type": "code",
   "source": "df_foodcodes_description = pd.read_sas(\"data/DRXFCD_H.xpt\")",
   "id": "5249bb28a34edf5c",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Check if foodcodes are able to be linked in the previous dataset of the food interviews",
   "id": "6e0fcc14f94888cc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "95330100 in df_foodcodes_description.DRXFDCD.unique()\n",
   "id": "ed16c0124b0b4a62"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The code above was taken from df_day1, so we can match the food codes with the descriptions.",
   "id": "3c735cbe355c8439"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T00:42:29.457957Z",
     "start_time": "2024-12-06T00:42:29.451673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_foodcodes_description[\"DRXFDCD\"] = df_foodcodes_description[\"DRXFDCD\"].apply(lambda x: int(x))\n",
    "df_foodcodes_description"
   ],
   "id": "6cc4a97e4b354ca5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       DRXFDCD                                            DRXFCSD  \\\n",
       "0     11000000                                     b'MILK, HUMAN'   \n",
       "1     11100000                                       b'MILK, NFS'   \n",
       "2     11111000                                     b'MILK, WHOLE'   \n",
       "3     11111100                         b'MILK, LOW SODIUM, WHOLE'   \n",
       "4     11111150                  b'MILK, CALCIUM FORTIFIED, WHOLE'   \n",
       "...        ...                                                ...   \n",
       "8531  95323000                       b'SPORTS DRINK, LOW CALORIE'   \n",
       "8532  95330100         b'FLUID REPLACEMENT, ELECTROLYTE SOLUTION'   \n",
       "8533  95330500          b'FLUID REPLACEMENT, 5% GLUCOSE IN WATER'   \n",
       "8534  95341000  b'FUZE SLENDERIZE FORTIFIED LOW CALORIE FRUIT ...   \n",
       "8535  95342000                     b'MONAVIE ACAI BLEND BEVERAGE'   \n",
       "\n",
       "                                                DRXFCLD  \n",
       "0                                        b'Milk, human'  \n",
       "1                                          b'Milk, NFS'  \n",
       "2                                        b'Milk, whole'  \n",
       "3                            b'Milk, low sodium, whole'  \n",
       "4                     b'Milk, calcium fortified, whole'  \n",
       "...                                                 ...  \n",
       "8531                       b'Sports drink, low calorie'  \n",
       "8532         b'Fluid replacement, electrolyte solution'  \n",
       "8533          b'Fluid replacement, 5% glucose in water'  \n",
       "8534  b'FUZE Slenderize fortified low calorie fruit ...  \n",
       "8535                     b'MonaVie acai blend beverage'  \n",
       "\n",
       "[8536 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DRXFDCD</th>\n",
       "      <th>DRXFCSD</th>\n",
       "      <th>DRXFCLD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11000000</td>\n",
       "      <td>b'MILK, HUMAN'</td>\n",
       "      <td>b'Milk, human'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11100000</td>\n",
       "      <td>b'MILK, NFS'</td>\n",
       "      <td>b'Milk, NFS'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11111000</td>\n",
       "      <td>b'MILK, WHOLE'</td>\n",
       "      <td>b'Milk, whole'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11111100</td>\n",
       "      <td>b'MILK, LOW SODIUM, WHOLE'</td>\n",
       "      <td>b'Milk, low sodium, whole'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11111150</td>\n",
       "      <td>b'MILK, CALCIUM FORTIFIED, WHOLE'</td>\n",
       "      <td>b'Milk, calcium fortified, whole'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8531</th>\n",
       "      <td>95323000</td>\n",
       "      <td>b'SPORTS DRINK, LOW CALORIE'</td>\n",
       "      <td>b'Sports drink, low calorie'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8532</th>\n",
       "      <td>95330100</td>\n",
       "      <td>b'FLUID REPLACEMENT, ELECTROLYTE SOLUTION'</td>\n",
       "      <td>b'Fluid replacement, electrolyte solution'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8533</th>\n",
       "      <td>95330500</td>\n",
       "      <td>b'FLUID REPLACEMENT, 5% GLUCOSE IN WATER'</td>\n",
       "      <td>b'Fluid replacement, 5% glucose in water'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8534</th>\n",
       "      <td>95341000</td>\n",
       "      <td>b'FUZE SLENDERIZE FORTIFIED LOW CALORIE FRUIT ...</td>\n",
       "      <td>b'FUZE Slenderize fortified low calorie fruit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8535</th>\n",
       "      <td>95342000</td>\n",
       "      <td>b'MONAVIE ACAI BLEND BEVERAGE'</td>\n",
       "      <td>b'MonaVie acai blend beverage'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8536 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Interpretation of the data\n",
    "As we can see from the table above, each unique food identifier, is reprented by a binary notation. However, the proability that we can infer what food is vegatarian or not is going to be very difficult by hand, it depends on how many different ingredients there are. \n",
    "\n",
    "### Binary notation\n",
    "The column DRXFCSD and DRXFCLD, is represented by a binary string, b''. Such a notation might become an issue later on if we try to evaluate wheter a food item consist out of meat or not. So therefore let's transform the binary string into a list of individual words"
   ],
   "id": "4a40a4858557ea42"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T00:42:30.682865Z",
     "start_time": "2024-12-06T00:42:30.675482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def turn_binary_string_to_list(df):\n",
    "    df[\"food_list\"] = df[\"DRXFCSD\"].apply(lambda x: str(x).replace(\"b'\", \"\").replace(\"'\", \"\").split(\",\"))\n",
    "    return df\n",
    "df_foodcodes_description = turn_binary_string_to_list(df_foodcodes_description)"
   ],
   "id": "9b1931eab42a1590",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It is important to understand how many individual food items there are available. We might be able to use a trick to find if the ingredients contain meat or not. Or if there are not too many, we could do so by hand. ",
   "id": "a5686114447b1f1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T09:05:58.701839Z",
     "start_time": "2024-12-06T09:05:58.698153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "unique_elemnts_food = set([food for food_list in df_foodcodes_description.food_list.values for food in food_list])\n",
    "print(f\"There are {len(unique_elemnts_food)} unique ingredients in the foodcodes description\")"
   ],
   "id": "f7c0bab12fb26c7f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6191 unique ingredients in the foodcodes description\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T00:42:35.986240Z",
     "start_time": "2024-12-06T00:42:35.873380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def turn_food_df_to_dict(df):\n",
    "    food_code_dict = {}\n",
    "    df_food_code = df[[\"DRXFDCD\", \"food_list\"]]\n",
    "    for index, row in df_food_code.iterrows():\n",
    "        food_code_dict[row[\"DRXFDCD\"]] = row[\"food_list\"]\n",
    "    return food_code_dict\n",
    "food_code_dict = turn_food_df_to_dict(df_foodcodes_description)"
   ],
   "id": "954256d59f6b108f",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Use of LLM to create food codes\n",
    "Because the food codes are so diverse, it is not feasible to identify a resistance rule without relying on a large number of if-else statements to determine the appropriate food category. Our goal is to classify whether a food is vegetarian by leveraging an LLM to analyze each data row and identify whether the food description includes fish, red meat, white meat, poultry, dairy, or other food-related products; otherwise, it is labeled as “none.” This is implemented using an LLM through the LLM Connect python file, where the process is detailed. The classification is performed by providing the LLM with a carefully designed prompt, which is demonstrated in this notebook, in the code block below. The prompt is entered into GPT-4 mini, and the output, formatted in JSON, is then used to label the data and determine if an individual is vegetarian. While this approach may feel like venturing into a rabbit hole, it provides a structured and effective method for achieving the desired labeling.\n",
    "\n"
   ],
   "id": "85863491e350f9b5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "        system_message = \"\"\"\n",
    "                You are a food detecting agent that responds only in JSON mode.\n",
    "                Analyze the following list of JSON objects representing food meals and their ingredients.\n",
    "                \"\"\"\n",
    "        user_task = \"\"\"\n",
    "        You are a food detecting agent that responds only in JSON mode.\n",
    "        Analyze the following list of JSON objects representing food meals and their ingredients:\n",
    "        {{input_json}}\n",
    "        ---\n",
    "\n",
    "        For each ingredient in each meal, determine if it contains any of the following categories, you are allowed to \n",
    "        label multiple ingredients as 1:\n",
    "        - poultry\n",
    "        - red meat\n",
    "        - fish\n",
    "        - shellfish\n",
    "        - dairy products\n",
    "        - other animal products\n",
    "\n",
    "        Return the result as a JSON array of objects with the structure:\n",
    "        \"meals\": [\n",
    "            {\n",
    "                \"ingredient_list\": \"list of food ingredients\",\n",
    "                \"meal_number: unique_id\n",
    "                \"poultry\": 1 or 0,\n",
    "                \"red_meat\": 1 or 0,\n",
    "                \"fish\": 1 or 0,\n",
    "                \"shellfish\": 1 or 0,\n",
    "                \"dairy_products\": 1 or 0,\n",
    "                \"other_animal_products\": 1 or 0,\n",
    "                \"none\": 1 or 0\n",
    "            }\n",
    "        ]\n",
    "        Only return the array of jsons in dict formats, nothing else.\n",
    "        \n",
    "        \"\"\""
   ],
   "id": "6e4ba731c4ea8c64"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T04:00:34.350158Z",
     "start_time": "2024-12-06T00:42:59.138760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def turn_json_into_segments(json_to_divide, dict_per_chunk=30):\n",
    "    \n",
    "\n",
    "    smaller_json = {}\n",
    "    json_list_combined = []\n",
    "    for index,(key, json_dict) in enumerate(json_to_divide.items()):\n",
    "        if index % dict_per_chunk ==0 and index !=0:\n",
    "            json_list_combined.append(smaller_json)\n",
    "            smaller_json = {}\n",
    "        smaller_json[key] = json_dict\n",
    "    json_list_combined.append(smaller_json)\n",
    "    return json_list_combined\n",
    "    \n",
    "\n",
    "\n",
    "def detect_food_json_list_dict(json_list:str):\n",
    "    json_list = turn_json_into_segments(json_to_divide=json_list,\n",
    "                                        dict_per_chunk=30)    \n",
    "    \n",
    "    \n",
    "    \n",
    "    LLM_translator = LLMConnect.DetectFoodIngredients(model_name=\"gpt-4o-mini\", max_tokens=9069)\n",
    "    \n",
    "    complete_food_labeled_json_dict = []\n",
    "    \n",
    "    for index, json_dict in enumerate(json_list):\n",
    "        food_json= json.dumps(json_dict)\n",
    "        food_labeled_json = LLM_translator.detect_food_ingredients(input_json= food_json\n",
    "                                                               )\n",
    "        \n",
    "        complete_food_labeled_json_dict.append(food_labeled_json)\n",
    "    return complete_food_labeled_json_dict\n",
    "        \n",
    "        \n",
    "complete_food_json = detect_food_json_list_dict(json_list=food_code_dict)\n",
    "\n"
   ],
   "id": "ff5fc72e7b256e73",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f3/ykt1vfz96xz48try_trwdn440000gn/T/ipykernel_45696/823920892.py:24: UserWarning: WARNING! response_format is not default parameter.\n",
      "                response_format was transferred to model_kwargs.\n",
      "                Please confirm that response_format is what you intended.\n",
      "  LLM_translator = LLMConnect.DetectFoodIngredients(model_name=\"gpt-4o-mini\", max_tokens=9069)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_1.json\n",
      "save_file_path =  json/data_1.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_2.json\n",
      "save_file_path =  json/data_2.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_3.json\n",
      "save_file_path =  json/data_3.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_4.json\n",
      "save_file_path =  json/data_4.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_5.json\n",
      "save_file_path =  json/data_5.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_6.json\n",
      "save_file_path =  json/data_6.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_7.json\n",
      "save_file_path =  json/data_7.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_8.json\n",
      "save_file_path =  json/data_8.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_9.json\n",
      "save_file_path =  json/data_9.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_10.json\n",
      "save_file_path =  json/data_10.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_11.json\n",
      "save_file_path =  json/data_11.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_12.json\n",
      "save_file_path =  json/data_12.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_13.json\n",
      "save_file_path =  json/data_13.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_14.json\n",
      "save_file_path =  json/data_14.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_15.json\n",
      "save_file_path =  json/data_15.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_16.json\n",
      "save_file_path =  json/data_16.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_17.json\n",
      "save_file_path =  json/data_17.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_18.json\n",
      "save_file_path =  json/data_18.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_19.json\n",
      "save_file_path =  json/data_19.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_20.json\n",
      "save_file_path =  json/data_20.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_21.json\n",
      "save_file_path =  json/data_21.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_22.json\n",
      "save_file_path =  json/data_22.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_23.json\n",
      "save_file_path =  json/data_23.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_24.json\n",
      "save_file_path =  json/data_24.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_25.json\n",
      "save_file_path =  json/data_25.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_26.json\n",
      "save_file_path =  json/data_26.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_27.json\n",
      "save_file_path =  json/data_27.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_28.json\n",
      "save_file_path =  json/data_28.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_29.json\n",
      "save_file_path =  json/data_29.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_30.json\n",
      "save_file_path =  json/data_30.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_31.json\n",
      "save_file_path =  json/data_31.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_32.json\n",
      "save_file_path =  json/data_32.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_33.json\n",
      "save_file_path =  json/data_33.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_34.json\n",
      "save_file_path =  json/data_34.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_35.json\n",
      "save_file_path =  json/data_35.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_36.json\n",
      "save_file_path =  json/data_36.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_37.json\n",
      "save_file_path =  json/data_37.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_38.json\n",
      "save_file_path =  json/data_38.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_39.json\n",
      "save_file_path =  json/data_39.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_40.json\n",
      "save_file_path =  json/data_40.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_41.json\n",
      "save_file_path =  json/data_41.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_42.json\n",
      "save_file_path =  json/data_42.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_43.json\n",
      "save_file_path =  json/data_43.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_44.json\n",
      "save_file_path =  json/data_44.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_45.json\n",
      "save_file_path =  json/data_45.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_46.json\n",
      "save_file_path =  json/data_46.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_47.json\n",
      "save_file_path =  json/data_47.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_48.json\n",
      "save_file_path =  json/data_48.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_49.json\n",
      "save_file_path =  json/data_49.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_50.json\n",
      "save_file_path =  json/data_50.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_51.json\n",
      "save_file_path =  json/data_51.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_52.json\n",
      "save_file_path =  json/data_52.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_53.json\n",
      "save_file_path =  json/data_53.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_54.json\n",
      "save_file_path =  json/data_54.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_55.json\n",
      "save_file_path =  json/data_55.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_56.json\n",
      "save_file_path =  json/data_56.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_57.json\n",
      "save_file_path =  json/data_57.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_58.json\n",
      "save_file_path =  json/data_58.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_59.json\n",
      "save_file_path =  json/data_59.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_60.json\n",
      "save_file_path =  json/data_60.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_61.json\n",
      "save_file_path =  json/data_61.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_62.json\n",
      "save_file_path =  json/data_62.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_63.json\n",
      "save_file_path =  json/data_63.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_64.json\n",
      "save_file_path =  json/data_64.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_65.json\n",
      "save_file_path =  json/data_65.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_66.json\n",
      "save_file_path =  json/data_66.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_67.json\n",
      "save_file_path =  json/data_67.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_68.json\n",
      "save_file_path =  json/data_68.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_69.json\n",
      "save_file_path =  json/data_69.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_70.json\n",
      "save_file_path =  json/data_70.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_71.json\n",
      "save_file_path =  json/data_71.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_72.json\n",
      "save_file_path =  json/data_72.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_73.json\n",
      "save_file_path =  json/data_73.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_74.json\n",
      "save_file_path =  json/data_74.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_75.json\n",
      "save_file_path =  json/data_75.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_76.json\n",
      "save_file_path =  json/data_76.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_77.json\n",
      "save_file_path =  json/data_77.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_78.json\n",
      "save_file_path =  json/data_78.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_79.json\n",
      "save_file_path =  json/data_79.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_80.json\n",
      "save_file_path =  json/data_80.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_81.json\n",
      "save_file_path =  json/data_81.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_82.json\n",
      "save_file_path =  json/data_82.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_83.json\n",
      "save_file_path =  json/data_83.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_84.json\n",
      "save_file_path =  json/data_84.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_85.json\n",
      "save_file_path =  json/data_85.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_86.json\n",
      "save_file_path =  json/data_86.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_87.json\n",
      "save_file_path =  json/data_87.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_88.json\n",
      "save_file_path =  json/data_88.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_89.json\n",
      "save_file_path =  json/data_89.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_90.json\n",
      "save_file_path =  json/data_90.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_91.json\n",
      "save_file_path =  json/data_91.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_92.json\n",
      "save_file_path =  json/data_92.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_93.json\n",
      "save_file_path =  json/data_93.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_94.json\n",
      "save_file_path =  json/data_94.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_95.json\n",
      "save_file_path =  json/data_95.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_96.json\n",
      "save_file_path =  json/data_96.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_97.json\n",
      "save_file_path =  json/data_97.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_98.json\n",
      "save_file_path =  json/data_98.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data_99.json\n",
      "save_file_path =  json/data_99.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n",
      "I am sending a request to an LLM now\n",
      "save_file_path =  json/data.json\n",
      "save_file_path =  json/data.json\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T07:33:01.780561Z",
     "start_time": "2024-12-06T07:33:01.766505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"complete_food_codes.json\", \"w\") as f:\n",
    "    f.write(json.dumps(complete_food_json))"
   ],
   "id": "2cda675a6642614d",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T08:55:49.415055Z",
     "start_time": "2024-12-06T08:55:49.412294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"There are a total of {len(complete_food_json)} chunks of food jsons\")\n",
    "print(f\"For a total of {len([food for chunk in complete_food_json for food in chunk[\"meals\"]])} of individual food items\")"
   ],
   "id": "acf4cb14ec9b890e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 285 chunks of food jsons\n",
      "For a total of 8527 of individual food items\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Evaluating LLM output\n",
    "As we can see from above, there are a total of 8527 individual food items that the LLM has returned. The structure of each chunk can be seen below.\n",
    "\n",
    "`\"meals\": [\n",
    "            {\n",
    "                \"ingredient_list\": \"list of food ingredients\",\\n\n",
    "                \"meal_number: unique_id\n",
    "                \"poultry\": 1 or 0,\n",
    "                \"red_meat\": 1 or 0,\n",
    "                \"fish\": 1 or 0,\n",
    "                \"shellfish\": 1 or 0,\n",
    "                \"dairy_products\": 1 or 0,\n",
    "                \"other_animal_products\": 1 or 0,\n",
    "                \"none\": 1 or 0\n",
    "            }\n",
    "        ]`\n",
    "        \n",
    "We now have a list of chunks, each containing 30 individual food items. The first step is to create a large dictionary where each food number serves as the key, and the corresponding food codes are stored as the values. Once this dictionary is constructed, we need to verify that all data values are correctly loaded and accurately reflect the intended information. After ensuring the data’s accuracy, the final step is to match each individual food item to the corresponding entries in the food record table. This process ensures the integration and alignment of data for further analysis."
   ],
   "id": "9d6763860b6edc2f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T09:29:06.705389Z",
     "start_time": "2024-12-06T09:29:06.664433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from copy import deepcopy\n",
    "chunked_food_json = deepcopy(complete_food_json)"
   ],
   "id": "2251e332e1862af3",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T09:29:07.417103Z",
     "start_time": "2024-12-06T09:29:07.412673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def turn_json_chunks_df(json_chunks):\n",
    "    complete_json = []\n",
    "    for chunk in json_chunks:\n",
    "        # Check if meals is in the chunk\n",
    "        if \"meals\" in chunk:\n",
    "            complete_json.extend(chunk[\"meals\"])\n",
    "        # If the llm named the chunk differently\n",
    "        elif len(chunk.keys()) == 1:\n",
    "            key_name = list(chunk.keys())[0]\n",
    "            complete_json.extend(chunk[key_name])\n",
    "        # If the LLM accidentally didn't give a key for the chunk\n",
    "        elif len(chunk.keys()) == 9:\n",
    "            complete_json.append(chunk)\n",
    "        else:\n",
    "            raise Exception(\"there is an issue with formatting\")\n",
    "            \n",
    "            \n",
    "        \n",
    "    return complete_json\n",
    "        \n",
    "exploded_food_json = turn_json_chunks_df(chunked_food_json)\n",
    "len(exploded_food_json)"
   ],
   "id": "68e3bb427afececc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8527"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
